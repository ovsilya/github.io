{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3dff67-9418-43d7-a0ae-b759255f8c1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Classify**\n",
    "\n",
    "This endpoint classifies text into one of several classes by passing a few examples. For the default small, medium, and large models, we create a classifier using our Representational model. For the xlarge default model, we construct a few-shot classifier prompt that is passed to our Generative model to predict a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c1f04d-655a-4d63-a2f3-97414d1ba645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cohere\n",
    "import cohere\n",
    "from cohere.classify import Example\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f511eab5-05b6-4614-92a6-503900549cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the values should be structured as {text:{},label:{}}\n",
    "import pandas as pd\n",
    "\n",
    "# df_train = pd.read_csv('rm_synthetic_data/train/RM_bias_detection_train.csv', header=None)\n",
    "df_train = pd.read_csv('rm_synthetic_data/train/train_church_binary.csv', header=None)\n",
    "# df_train = pd.read_csv('rm_synthetic_data/train/empty_train_5_5.csv', header=None)\n",
    "\n",
    "df_train.columns = ['reviews','lables']\n",
    "train_samples = []\n",
    "\n",
    "for index, sample in df_train.iterrows():\n",
    "    train_samples.append(Example(sample['reviews'], str(sample['lables'])))\n",
    "    \n",
    "# df_test = pd.read_csv('rm_synthetic_data/test/RM_bias_detection_test.csv', header=None)\n",
    "df_test = pd.read_csv('rm_synthetic_data/test/test_church_binary.csv', header=None)\n",
    "df_test.columns = ['reviews','lables']\n",
    "\n",
    "# #################################################################\n",
    "train_reviews_list = list(df_train['reviews'])\n",
    "test_reviews_list = list(df_test['reviews'])\n",
    "\n",
    "train_lables_list = list(df_train['lables'])\n",
    "test_lables_list = list(df_test['lables'])\n",
    "\n",
    "# print(df_train.iloc[5])\n",
    "# print(df_train['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e223c-a5d6-47bd-bea7-abee8a390fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client('HGr7Vhg5sPITDWi2tXk6J7KrAEizn1Mc8Tkg6k4o')\n",
    "response = co.classify(model='small',inputs = test_reviews_list, examples = train_samples)\n",
    "\n",
    "# response = co.classify(model='small',inputs = ['this house is located with close proximity to house of prayer '], examples = train_samples )\n",
    "# print(response.classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0380c9e4-1aa2-4010-a3ad-d993b9242b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The confidence levels of the labels are: {}'.format(response.classifications))\n",
    "# print(response.classifications)\n",
    "classify_predictions = []\n",
    "for item in range (0,len(response.classifications)):\n",
    "    classify_predictions.append(response.classifications[item].prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000808b-ce84-41f6-acae-c0e188d9d730",
   "metadata": {},
   "source": [
    "# **Embed**\n",
    "\n",
    "This endpoint returns text embeddings. An embedding is a list of floating point numbers that captures semantic information about the text that it represents. Embeddings can be used to create text classifiers as well as empower semantic search. To learn more about embeddings, see the embedding page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b267f-54cc-4e49-8cb7-821c478aeb0d",
   "metadata": {},
   "source": [
    "## **Get the embeddings of the reviews:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3665b99-9b61-48d1-9e52-c5e4a0e20cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train_reviews = co.embed(texts=train_reviews_list)\n",
    "embeddings_test_reviews = co.embed(texts=test_reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8814dbe-e674-4dea-831c-0d61cc7dc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(embeddings_train_reviews))\n",
    "# print(embeddings_train_reviews.embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da887a-06af-44e2-9cf8-82c2e6c4be19",
   "metadata": {},
   "source": [
    "## **Train a classifier using the training set**\n",
    "\n",
    "Now that we have the embedding we can train our classifier. We'll use an SVM from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c996f5e-d067-4af0-ae99-3f8daec56686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(class_weight='balanced'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the support vector machine, with class_weight='balanced' because\n",
    "# our training set has roughly an equal amount of positive and negative\n",
    "# sentiment sentences\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC(class_weight='balanced'))\n",
    "\n",
    "# fit the support vector machine\n",
    "svm_classifier.fit(embeddings_train_reviews.embeddings, train_lables_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052aa422-b3f0-4a05-a8ee-923eb132eede",
   "metadata": {},
   "source": [
    "## **Evaluate the performance of the classifier on the testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588be7ab-44f1-4a73-992f-56631cc46233",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = svm_classifier.score(embeddings_test_reviews.embeddings, test_lables_list)\n",
    "embed_predictions = svm_classifier.predict(embeddings_test_reviews.embeddings)\n",
    "# print(f\"Validation accuracy on Small is {100*score}%!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b4139e-30cd-4d3c-83eb-8059665dffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Embed Endpoint Predictions: ', embed_predictions)\n",
    "# print('Classify Endpoint Predictions: ', classify_predictions)\n",
    "\n",
    "######################### calculate accuracy for Classify Endpoint #####################\n",
    "a = test_lables_list\n",
    "b = [eval(i) for i in classify_predictions]\n",
    "\n",
    "score_classify = len([a[i]\n",
    "   for i in range(0, len(a)) if a[i] == b[i]\n",
    "]) / len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afb348-7dce-45cd-8d41-e470cea205bd",
   "metadata": {},
   "source": [
    "## **XGBoost Classifier Head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f6e64c-30ab-4378-8c94-cf89f9230d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(embeddings_train_reviews.embeddings, train_lables_list)\n",
    "\n",
    "xgb_pred_train = xgb_model.predict(embeddings_train_reviews.embeddings)\n",
    "xgb_pred_test = xgb_model.predict(embeddings_test_reviews.embeddings)\n",
    "\n",
    "# print(\"confusion matrix on training set\\n\",confusion_matrix(train_lables_list, xgb_pred_train))\n",
    "# print(\"confusion matrix on testset\\n\",confusion_matrix(test_lables_list, xgb_pred_test))\n",
    "print(xgb_pred_test)\n",
    "\n",
    "######################### calculate accuracy for Embed+XGB Endpoint #####################\n",
    "c = test_lables_list\n",
    "d = xgb_pred_test\n",
    "\n",
    "score_XGB = len([c[i]\n",
    "   for i in range(0, len(c)) if c[i] == d[i]\n",
    "]) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6759604-d543-4df5-b538-146ba949cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### calculate F1 score #########################\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "f1_classify = round(f1_score(test_lables_list, b),2)\n",
    "precision_classify = round(precision_score(test_lables_list, b),2)\n",
    "recall_classify = round(recall_score(test_lables_list, b),2)\n",
    "\n",
    "f1_embed = round(f1_score(test_lables_list, embed_predictions),2)\n",
    "precision_embed = round(precision_score(test_lables_list, embed_predictions),2)\n",
    "recall_embed = round(recall_score(test_lables_list, embed_predictions),2)\n",
    "\n",
    "f1_xgb = round(f1_score(test_lables_list, xgb_pred_test),2)\n",
    "precision_xgb = round(precision_score(test_lables_list, xgb_pred_test),2)\n",
    "recall_xgb = round(recall_score(test_lables_list, xgb_pred_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c10807d9-617e-4f4c-9fe0-94f0fb7149fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "from datetime import date, datetime\n",
    "\n",
    "Predictions_pd = pd.DataFrame(columns = ['Test_Samples',\"GroundTruth\",'Embed+SVM','Classify',\"Embed+XGB\"])\n",
    "Predictions_pd['Test_Samples'] = test_reviews_list\n",
    "Predictions_pd['Embed+SVM'] = embed_predictions\n",
    "Predictions_pd['Classify'] = classify_predictions\n",
    "Predictions_pd['GroundTruth'] = test_lables_list\n",
    "Predictions_pd['Embed+XGB'] = xgb_pred_test\n",
    "\n",
    "Predictions_pd.loc[len(Predictions_pd.index)] = [\"accuracy\", \"--\", round(score,2), round(score_classify,2), round(score_XGB,2)]\n",
    "Predictions_pd.loc[len(Predictions_pd.index)] = [\"f1 score\", \"--\", f1_embed, f1_classify, f1_xgb]\n",
    "Predictions_pd.loc[len(Predictions_pd.index)] = [\"precision\", \"--\", precision_embed, precision_classify, precision_xgb]\n",
    "Predictions_pd.loc[len(Predictions_pd.index)] = [\"recall\", \"--\", recall_embed, recall_classify, recall_xgb]\n",
    "\n",
    "today = date.today()\n",
    "Predictions_pd.to_csv('classify_embed_test_prediciton_church_{}.csv'.format(today), sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3dc5c-e967-4cba-982e-8cfb14aefd6b",
   "metadata": {},
   "source": [
    "This was a small scale example, meant as a proof of concept and designed to illustrate how you can build a custom classifier quickly using a small amount of labelled data and Cohere's embeddings. Increase the number of training examples to achieve better performance on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9eaea-f149-44e9-b7a1-d75ab49a436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.Client('KWCowTYXNCAIxpIw4pd73viKBAtfoEe1OzG6lzK1')\n",
    "response = co.generate(\n",
    "  model='large',\n",
    "  prompt='The following contains biased statement about a real estate listing. Biased statements contain negative or positive opinions based on objective factors.\\n\\n statement: Hispanic community in the neighbourhood may reduce the price of the property. \\n--\\nstatement: There is a big community of Latino families in the area. \\n--\\nstatement: American Indians make up an overwhelming majority in the neighborhood. \\n--\\nstatement: There is an influx of Asian community buying properties in the area. \\n--\\nstatement: There is a lack of African American families in the neighborhood. \\n--\\nstatement: There is a growing Native Hawaiian population in this area. \\n--\\nstatement: Pacific Islander community has been growing in the area. \\n--\\nstatement:',\n",
    "  max_tokens=100,\n",
    "  temperature=0.8,\n",
    "  k=0,\n",
    "  p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop_sequences=[\"--\"],\n",
    "  return_likelihoods='NONE',\n",
    "  num_generations=5)\n",
    "  \n",
    "for i in range(5):\n",
    "    print('Prediction: {}'.format(response.generations[i].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52412657-525e-47b4-9c3b-2482acfb7b4f",
   "metadata": {},
   "source": [
    "# **Cohere Platform CLI Tool**\n",
    "\n",
    "The Cohere Platform CLI Tool is an alternative to our web interface, which allows you to login to your Cohere account, manage API Keys, and run finetunes.\n",
    "\n",
    "This CLI tool is POSIX compliant (you can expect arguments and flags to work the same as they do with other popular CLI tools). Don't forget to use co --help or co [COMMAND] --help if you don't want to check back to this page!\n",
    "\n",
    "Install#\n",
    "\n",
    "1. Download the package for your OS. Use the following curl command to download the correct package, or use a download link below to get a tar.\n",
    "\n",
    "https://github.com/cohere-ai/co/releases/latest/download/co_linux_x86_64.tar.gz\n",
    "\n",
    "2. Move the binary into your $PATH (if you'd like to).\n",
    "3. Authenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe289c1-ce7e-484a-a2cd-d4145b56b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/cohere-ai/co/main/install.sh | sh\n",
    "# mkdir -p /usr/local/bin\n",
    "# mv ./co /usr/local/bin/\n",
    "# co auth login --email=EMAIL"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m96",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m96"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
